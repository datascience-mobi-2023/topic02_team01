{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Protein sequence Alignment of TEM-1 with 100 homologs**:\n",
    "NCBI Blast protein alignment is used to align TEM-1 beta lactamase with 100 proteins.\n",
    "For the blast search RefSeq library was selected. \n",
    "\n",
    "Results:\n",
    "The alignemnt comprises 95 class A beta lactamases and 5 serine hydrolases. The Identity which reports on the percantage of matching amino acids between the aligned sequece and TEM-1 ranges from 47.5% - 99.65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Alignment Analysis** \n",
    "1. Alignment Heatmap & Consensus Sequence\n",
    "2. Calculation of conservation score   \n",
    "    2.1 Pei & Grishin conservation  \n",
    "    2.2 Shannon entropy  \n",
    "    2.3 Comparision of Pei & Grishin and Shannon conservation  \n",
    "    - Barplot\n",
    "    - Correlation scatter plot \n",
    "3. Residue categorization by DMS and Conservation\n",
    "    - Correlation scatter plots\n",
    "    - Categorization in bar plots \n",
    "    \n",
    "4. Concensus Sequence Alignment  \n",
    "    4.1 Self calculated concensus (SCC)  \n",
    "    4.2 Emboss Concensus Sequence (ECS)  \n",
    "    - Blosum62, PAM250\n",
    "    - Blosum90\n",
    "    - PAM460\n",
    "    4.3 Optimization of BLOSUM90 alignment\n",
    "    \n",
    "5. Extended : DMS trend at important positions\n",
    "\n",
    "6. Extended: Hypothesis testing \n",
    "\n",
    "        \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Alignment Heatmap & Concensus Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T12:13:44.911005900Z",
     "start_time": "2023-07-17T12:13:44.645378100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, Bio, matplotlib.pyplot as plot\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Creating the parameters for the heatmap\n",
    "\n",
    "font = {'family': 'monospace',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }\n",
    "\n",
    "palette = [\n",
    "    '#C8C8C8', '#145AFF', '#00DCDC', '#E60A0A', '#E6E600',\n",
    "    '#00DCDC', '#E60A0A', '#EBEBEB', '#8282D2', '#0F820F', \n",
    "    '#0F820F', '#145AFF', '#E6E600', '#3232AA', '#DC9682', \n",
    "    '#FA9600', '#FA9600', '#B45AB4', '#3232AA', '#0F820F', \n",
    "    '#FFFFFF']\n",
    "\n",
    "\n",
    "aa = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "\n",
    "# This is the fasta file with the 100 aligned sequences\n",
    "fasta_file = \"dataSources/MSA_datasets/TEM-1_Alignment_100_Homolgs.aln\"\n",
    "sequences = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "#Converting fasta to list with 286 Positions\n",
    "msa = list(SeqIO.parse(fasta_file,'fasta'))\n",
    "L = len(msa[0].seq)#286 Positions\n",
    "N = len(msa)#101 rows\n",
    "\n",
    "#Creating empty data frame for the counted amino acids at each position\n",
    "freq = np.zeros([L,21])\n",
    "\n",
    "#creating the concensus sequence\n",
    "concensus = np.zeros(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T12:13:45.130009600Z",
     "start_time": "2023-07-17T12:13:44.660987600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Counts the amino acids for each position and selects the amino acid with the highest frequency for the concensus sequnece\n",
    "\n",
    "for i in range(0,N):\n",
    "    for j in range(0,L):\n",
    "        j_aa = aa.find(msa[i].seq[j])\n",
    "        freq[j,j_aa] = freq[j,j_aa] + 1 \n",
    "for i in range(0, L):\n",
    "    concensus[i] = freq[i].argmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T12:13:45.208140800Z",
     "start_time": "2023-07-17T12:13:44.723493100Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     axes\u001B[38;5;241m.\u001B[39mtext(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5\u001B[39m,posit, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeq \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m(\u001B[38;5;28mstr\u001B[39m(j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)))\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, L):\n\u001B[0;32m     19\u001B[0m         axes\u001B[38;5;241m.\u001B[39mtext(\u001B[38;5;28mfloat\u001B[39m(i),posit, msa[j]\u001B[38;5;241m.\u001B[39mseq[i],\n\u001B[1;32m---> 20\u001B[0m             bbox\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfacecolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpalette\u001B[49m\u001B[43m[\u001B[49m\u001B[43maa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsa\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m,fontdict\u001B[38;5;241m=\u001B[39mfont)\n\u001B[0;32m     22\u001B[0m figure\n",
      "\u001B[1;31mTypeError\u001B[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "#Heatmap\n",
    "conservation = np.sqrt(np.sum((np.square(freq/N - 0.05)),axis=1))\n",
    "figure = plot.figure(figsize=(20,2))\n",
    "axes = plot.axes([0,0,1,1]);\n",
    "plot.close()\n",
    "\n",
    "axes.bar(range(0,L),conservation, align='edge', linewidth = 0, color = 'red')\n",
    "axes.set_ylabel('Conservation')\n",
    "\n",
    "spacing_scale = axes.get_ylim()[1]/6\n",
    "spacing = spacing_scale*2\n",
    "\n",
    "seq_display = np.sort(np.random.randint(0,N,[5]))\n",
    "\n",
    "for j in seq_display:\n",
    "    posit = -float(np.where(seq_display == j)[0][0]) * spacing_scale - spacing\n",
    "    axes.text(-5,posit, \"Seq \"+(str(j+1)))\n",
    "    for i in range(0, L):\n",
    "        axes.text(float(i),posit, msa[j].seq[i],\n",
    "            bbox=dict(facecolor=palette[aa.find(msa[j].seq[i])], alpha=0.5),fontdict=font)\n",
    "        \n",
    "figure\n",
    "\n",
    "#sometimes this chunk produces an error randomly. In this case we had to restart pycharm for it to run correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "#shows the concensus sequence at the bottom\n",
    "posit = posit - spacing\n",
    "axes.text(-5,posit, \"Concensus\")\n",
    "for i in range(0, L):\n",
    "    axes.text(float(i),posit, 'ARNDCQEGHILKMFPSTWYV-'[int(concensus[i])] ,\n",
    "                bbox=dict(facecolor=palette[int(concensus[i])], \n",
    "                alpha=0.5),fontdict=font)\n",
    "    \n",
    "figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculatuion of Conservation score & modeling of concensus sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Pei & Grishin conservation\n",
    "Measures the root mean square deviation between the amino acid distribution p~ia and the average amino acid distribution over the whole alignment, which is 1/20 as a range of 20 amino acids can mutate into each position. \n",
    "\n",
    "     V = √∑(p_ia/N-E)^2\n",
    "     max: V = 0 (each a 5x times in alignemnt)\n",
    "     min: V = 0.95 (total conserved position)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "conservation = np.sqrt(np.sum((np.square(freq/N - 0.05)),axis=1))\n",
    "figure = plot.figure(figsize=(20,2))\n",
    "axes = plot.axes([0,0,1,1]);\n",
    "plot.close()\n",
    "\n",
    "axes.bar(range(0,L),conservation, align='edge', linewidth = 0, color = 'red')\n",
    "axes.set_ylabel('Conservation')\n",
    "\n",
    "spacing_scale = axes.get_ylim()[1]/6\n",
    "spacing = spacing_scale*2\n",
    "\n",
    "seq_display = np.sort(np.random.randint(0,N,[5]))#\n",
    "\n",
    "figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Shannon entropy \n",
    "The entropy H for each position with amino acid frequency p_ia is:\n",
    "\n",
    "    H = - ∑p_ialog2(p_ia)\n",
    "    min: H = 0 (all 100 positions equal)\n",
    "    max: H = 4.321 (each amino acid occurs 5 times in alignment)\n",
    "\n",
    "- the negative sum of the logarithmus base two multiplied by the proportion of amino acid a is calculated for each amino acid a = 1-20 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "#positions without occurence of one amino acid have values of -inf (value=0, log=-inf )\n",
    "# convert them to nan\n",
    "with pd.option_context('mode.use_inf_as_na',True):\n",
    "    log_nmb = freq/N* np.log2(freq/N)\n",
    "    log_nmb[ log_nmb == -np.inf] = np.nan \n",
    "\n",
    "#ignore nan and calculate the entropy for each position\n",
    "conservation_Shannon = np.nansum(log_nmb, axis=1,)*-1\n",
    "\n",
    "\n",
    "figure = plot.figure(figsize=(20,2))\n",
    "axes = plot.axes([0,0,1,1]);\n",
    "plot.close()\n",
    "\n",
    "axes.bar(range(0,L),conservation_Shannon, align='edge', linewidth = 0, color = 'red')\n",
    "axes.set_ylabel('Conservation')\n",
    "\n",
    "spacing_scale = axes.get_ylim()[1]/6\n",
    "spacing = spacing_scale*2\n",
    "\n",
    "seq_display = np.sort(np.random.randint(0,N,[5]))\n",
    "\n",
    "figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Comparision of Pei & Grishin and Shannon conservation\n",
    "Differences of the conservation scores: \n",
    "\n",
    "- Pei & Grishin conservation increases with conservation score whereas conservation decreases with increasing Shannon entropy  \n",
    "\n",
    "- Shannon entropy measures the amount of disorder for each position which is quite sensitive for rare amino acids occurences\n",
    "\n",
    "- Pei & Grishin conservation is less senistive because the difference between frequencies instead of their ratio is used to measure the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(20, 6))\n",
    "axes1 = plt.subplot(211)\n",
    "axes2 = plt.subplot(212)\n",
    "\n",
    "width = 0.35 \n",
    "x = np.arange(L) \n",
    "\n",
    "axes1.bar(x, conservation_Shannon, width, align='center', linewidth=0, color='red', label='Conservation Shannon')\n",
    "axes1.set_ylabel('Conservation')\n",
    "\n",
    "axes2.bar(x, conservation, width, align='center', linewidth=0, color='blue', label='Pei & Grishin')\n",
    "axes2.set_ylabel('Conservation')\n",
    "\n",
    "spacing_scale = axes1.get_ylim()[1] / 6\n",
    "spacing = spacing_scale * 2\n",
    "\n",
    "axes1.legend()\n",
    "axes2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better comparability, the conservation scores are z-normalizated.  \n",
    "The scores should be directling opposing to each other after z-normalisation, as the same trend has the opposite sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export DMS_Conservation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cut signal sequence 0-23 \n",
    "conservation_core_V = conservation[23:]\n",
    "conservation_Shannon_cut = conservation_Shannon[23:]\n",
    "\n",
    "#data frame with mean z-normalized position scores\n",
    "df_mean = pd.read_pickle('dataSources/handovers/position_means.pkl')\n",
    "df_DMS_Conserv = df_mean[['mean_Stiffler_z', 'mean_Deng_z', 'mean_Firnberg_z', 'mean_all_z']].copy()\n",
    "\n",
    "#adding conservation scores \n",
    "df_DMS_Conserv['Pei&Grishin'] = conservation_core_V\n",
    "df_DMS_Conserv_S = df_DMS_Conserv.copy()\n",
    "df_DMS_Conserv_S['Conserved_Shannon'] = conservation_Shannon_cut\n",
    "\n",
    "print(df_DMS_Conserv_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "#z-normalisation of Shannon conservation und Pei Grishin conservation\n",
    "df_DMS_Conserv_S_Norm = df_DMS_Conserv_S.copy()\n",
    "\n",
    "def z_score(column):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    z_scores = (column - mean) / std\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "df_DMS_Conserv_S_Norm['Conserved_Shannon'] = z_score(df_DMS_Conserv_S['Conserved_Shannon'])\n",
    "df_DMS_Conserv_S_Norm['Pei&Grishin'] = z_score(df_DMS_Conserv_S['Pei&Grishin'])\n",
    "\n",
    "#Dataframe export\n",
    "df_DMS_Conserv_S_Norm.to_csv('dataSources/handovers/DMS_Conservation.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.942257800Z"
    }
   },
   "outputs": [],
   "source": [
    "# P&G and Shannon conservation z-normalized\n",
    "DMS_Conservation  = pd.read_csv('dataSources/handovers/DMS_Conservation.csv')\n",
    "\n",
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects1 = ax.bar(x, DMS_Conservation['Conserved_Shannon'], width, label='Shannon')\n",
    "rects2 = ax.bar(x, DMS_Conservation['Pei&Grishin'], width, label='Pei & Grishin')\n",
    "\n",
    "ax.set_xlabel('Position')\n",
    "ax.set_ylabel('Conservation Score')\n",
    "ax.set_title('Comparision of Conservation Scores')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite bars mean the same trend and are predominantly represented, also the conservation strength (lenght of bars) seems to be quite equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculation of correlation score \n",
    "corr = np.corrcoef(DMS_Conservation['Conserved_Shannon'], DMS_Conservation['Pei&Grishin'])\n",
    "print(corr)\n",
    "\n",
    "plt.scatter(DMS_Conservation['Conserved_Shannon'], DMS_Conservation['Pei&Grishin'])\n",
    "plt.xlabel('Shannon')\n",
    "plt.ylabel('Pei & Grishin')\n",
    "plt.title('Correlation of Shannon Entropy and Pei & Grishin Conservation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "     r = 0.99118175\n",
    "There is significant correlation between the conservation values of both calculation methods.  \n",
    "For further approach we deicided to use the Shannon Entropy as it is more sensitive.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Residue categorization by DMS and conservation\n",
    "\n",
    "In the following analysis we are going to verify the following hypothesis: \n",
    "\n",
    "I. High fragility (low DMS) conditions higher conservation    \n",
    "II. Conservation occurs only when necessary, thus at fragile residues    \n",
    "III. Thus, high robustness (high DMS) conditions lower conservation     \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "C_df_New = DMS_Conservation.copy()\n",
    "C_df_New['Position'] = range(24,287)\n",
    "\n",
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "rects1 = ax1.bar(x, C_df_New['Conserved_Shannon'], width, label='Shanon Conservation')\n",
    "rects2 = ax1.bar(x, C_df_New['mean_all_z'], width, bottom=C_df_New['Conserved_Shannon'], label='mean DMS')\n",
    "\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Mean DMS with Shannon Conservation')\n",
    "ax1.legend()\n",
    "\n",
    "rects3 = ax2.bar(x, C_df_New['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects4 = ax2.bar(x, C_df_New['mean_Stiffler_z'], width, bottom=C_df_New['Conserved_Shannon'], label='mean Stiffler')\n",
    "\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Scores')\n",
    "ax2.set_title('Mean Stiffler with Shannon Conservation')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "C_df_New = DMS_Conservation.copy()\n",
    "C_df_New['Position'] = range(24,287)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(50, 20))\n",
    "\n",
    "for i, col in enumerate(C_df_New.columns):\n",
    "    if col == 'Position' or col == 'Pei&Grishin' or col =='Conserved_Shannon':\n",
    "        continue\n",
    "    else:\n",
    "        axs[0,i-1].scatter(C_df_New[col], C_df_New['Pei&Grishin'])\n",
    "        axs[1,i-1].scatter(C_df_New[col], C_df_New['Conserved_Shannon'])\n",
    "        axs[0, i-1].set_xlabel(col)  \n",
    "        axs[0, i-1].set_ylabel('Conservation score')  \n",
    "        \n",
    "        axs[1, i-1].set_xlabel(col)  \n",
    "        axs[1, i-1].set_ylabel('Conservation score')  \n",
    "\n",
    "\n",
    "plt.xlabel('DMS')\n",
    "plt.ylabel('Conservation score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "cor_df = pd.DataFrame(columns=['Shannon', 'Pei&Grishin'])\n",
    "\n",
    "for col in C_df_New.columns:\n",
    "    if col == 'Position':\n",
    "        continue\n",
    "    else:\n",
    "        cor_v = C_df_New[col].corr(C_df_New['Pei&Grishin'])\n",
    "        cor_S = C_df_New[col].corr(C_df_New['Conserved_Shannon'])\n",
    "        cor_df = pd.concat([cor_df, pd.DataFrame({'Pei&Grishin': [cor_v], 'Shannon': [cor_S]}, index=[col])])\n",
    "\n",
    "cor_df = cor_df.rename(index={'Stiffler': 0, 'Deng': 1, 'Firnberg': 2, 'Mean': 3, 'variance': 4, 'Shannon': 5})\n",
    "display(cor_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "### Scatter plots: \n",
    "The scatter plots of Pei and Grsihin (upper row) and Shannon (lower row) with each DMS data set are almost exactly identical but opposed, as the same trend has opposite signs in the conservation formulars.  \n",
    "Across the DMS data sets ther scatter plots show a consistent picture.  \n",
    "Two clusters can be detected, located in the corners of high conservation and low DMS scores and low conservation and high DMS scores.  \n",
    "Both hypothesis can be maintained by these results.\n",
    "\n",
    "### Correlation scores:\n",
    "There are only minor differences in the correlation between Shannon and P&G with the datasets.\n",
    "The absolute correlation values are in range of r = 0.53 - 0.71  \n",
    "The correlation of  Deng DMS scores is the lowest with r = 0.53, while the correlation of Firnberg, Stiffler and the merged model are similar and range from r= 0.66 - 0.72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax1s = plt.subplots()\n",
    "\n",
    "# Position of interest\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Stiffler_z'], 0),\n",
    "       width, color='blue', label='Position of interest')\n",
    "\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Stiffler_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Stiffler_z'], 0),\n",
    "       color='blue', alpha=0.5)\n",
    "\n",
    "# Unneccessary Conserved\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Stiffler_z'], 0),\n",
    "       width,\n",
    "       color='green', label='Unnecessary Conserved')\n",
    "\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, \n",
    "       color='green', alpha=0.5)\n",
    "\n",
    "# Destructive Position\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Stiffler_z'], 0),\n",
    "       width, \n",
    "       color='orange', label='Destructive Position')\n",
    "\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width,  \n",
    "       color='orange', alpha=0.5)\n",
    "\n",
    "# Random\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Stiffler_z'], 0),\n",
    "       width, color='red', label='Random Position')\n",
    "\n",
    "ax1s.bar(x, np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Stiffler_z'],0 ),\n",
    "       color='red', alpha=0.5)\n",
    "\n",
    "ax1s.set_xlabel('Position')\n",
    "ax1s.set_ylabel('Scores')\n",
    "ax1s.set_title('Shannon Entropy of Stiffler mean DMS')\n",
    "ax1s.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax2m = plt.subplots()\n",
    "\n",
    "# Position of interest\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_all_z'], 0),\n",
    "       width, color='blue', label='Position of interest')\n",
    "\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_all_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_all_z'], 0),\n",
    "       color='blue', alpha=0.5)\n",
    "\n",
    "# Unneccessary Conserved\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_all_z'], 0),\n",
    "       width,\n",
    "       color='green', label='Unnecessary Conserved')\n",
    "\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, \n",
    "       color='green', alpha=0.5)\n",
    "\n",
    "# Destructive Position\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_all_z'], 0),\n",
    "       width, \n",
    "       color='orange', label='Destructive Position')\n",
    "\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width,  \n",
    "       color='orange', alpha=0.5)\n",
    "\n",
    "# Random\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_all_z'], 0),\n",
    "       width, color='red', label='Random Position')\n",
    "\n",
    "ax2m.bar(x, np.where((C_df_New['mean_all_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_all_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_all_z'],0 ),\n",
    "       color='red', alpha=0.5)\n",
    "\n",
    "ax2m.set_xlabel('Position')\n",
    "ax2m.set_ylabel('Scores')\n",
    "ax2m.set_title('Shannon Entropy of merged model')\n",
    "ax2m.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax3f = plt.subplots()\n",
    "\n",
    "# Position of interest\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Firnberg_z'], 0),\n",
    "       width, color='blue', label='Position of interest')\n",
    "\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Firnberg_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Firnberg_z'], 0),\n",
    "       color='blue', alpha=0.5)\n",
    "\n",
    "# Unneccessary Conserved\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Firnberg_z'], 0),\n",
    "       width,\n",
    "       color='green', label='Unnecessary Conserved')\n",
    "\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, \n",
    "       color='green', alpha=0.5)\n",
    "\n",
    "# Destructive Position\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Firnberg_z'], 0),\n",
    "       width, \n",
    "       color='orange', label='Destructive Position')\n",
    "\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width,  \n",
    "       color='orange', alpha=0.5)\n",
    "\n",
    "# Random\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Firnberg_z'], 0),\n",
    "       width, color='red', label='Random Position')\n",
    "\n",
    "ax3f.bar(x, np.where((C_df_New['mean_Firnberg_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Firnberg_z'],0 ),\n",
    "       color='red', alpha=0.5)\n",
    "\n",
    "ax3f.set_xlabel('Position')\n",
    "ax3f.set_ylabel('Scores')\n",
    "ax3f.set_title('Shannon Entropy of Firnberg mean DMS')\n",
    "ax3f.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(24.0, 287.0, 1.0)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax4d = plt.subplots()\n",
    "\n",
    "# Position of interest\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Deng_z'], 0),\n",
    "       width, color='blue', label='Position of interest')\n",
    "\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Deng_z'] < 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Deng_z'], 0),\n",
    "       color='blue', alpha=0.5)\n",
    "\n",
    "# Unneccessary Conserved\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['mean_Deng_z'], 0),\n",
    "       width,\n",
    "       color='green', label='Unneccessary Conserved')\n",
    "\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] > 0) & (C_df_New['Conserved_Shannon'] < 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, \n",
    "       color='green', alpha=0.5)\n",
    "\n",
    "# Destructive Position\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Deng_z'], 0),\n",
    "       width, \n",
    "       color='orange', label='Destructive Position')\n",
    "\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] < 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width,  \n",
    "       color='orange', alpha=0.5)\n",
    "\n",
    "# Random\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Deng_z'], 0),\n",
    "       width, color='red', label='Random Position')\n",
    "\n",
    "ax4d.bar(x, np.where((C_df_New['mean_Deng_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['Conserved_Shannon'], 0),\n",
    "       width, bottom=np.where((C_df_New['mean_Stiffler_z'] > 0) & (C_df_New['Conserved_Shannon'] > 0), C_df_New['mean_Deng_z'],0 ),\n",
    "       color='red', alpha=0.5)\n",
    "\n",
    "ax4d.set_xlabel('Position')\n",
    "ax4d.set_ylabel('Scores')\n",
    "ax4d.set_title('Shannon Entropy of Deng mean DMS')\n",
    "ax4d.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "The following positions can be identified in the bar plots:\n",
    "\n",
    "1. Position of Interest (blue)\n",
    "    - DMS negative = Fragile \n",
    "    - Conservation = Negative\n",
    "2. Unnecessary conserved Position (green)\n",
    "    - DMS positive = Robust\n",
    "    - Conservation = Negative\n",
    "3. Random Positions\n",
    "    - DMS positive = Robust\n",
    "    - Conservation = Positive\n",
    "4. Destructive Position\n",
    "    - DMS negative = Fragile\n",
    "    - Conservation = Positive\n",
    "\n",
    "The conservation trends of the four DMS mean data sets are overall consitent, with only recognizable differences in the Deng conservation distribution.  \n",
    "In all four data sets positions of interest and random positions are predominant, which support the hypothesesis that fragile positions are conserved.\n",
    "Unnecessary conserved positions are rarely found, except in the deng distribution, in which a cluster of this category appears around position 230. Still the proportion of unneccessarry conserved positions is small across the data sets.That supports that conservation only occurs when necessary.\n",
    "Destructive positions contradict the evolutionary principle of fragile resdiues beeing conserved and do appear rarely in all data sets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Concensus Sequence Alignment \n",
    "The concensus sequence is commonly composed by the most frequent amino acids in a given alignment. Therefore evolutionary conservation can be estimated by the concensus sequence which is analysed in the following. \n",
    "The goal is to find correlation between conservation given by the concensus sequence and the DMS scores.\n",
    "\n",
    "The following trends are expected: \n",
    "\n",
    "1. Mismatches should only occure at random positions with high DMS and low conservation\n",
    "2. Fragile positions with high conservation (positions of interest), destructive positions and unneccessary conserved positions should not be among the mismatches\n",
    "3. Random positions should predominate\n",
    "\n",
    "### Alignment score\n",
    "The alignment score is a sum of match, mismatch, gap creation, and gap extension scores\n",
    "     S= Σ of costs (identities, replacements) - Σ of penalties (number of gaps x gap penalties)\n",
    "Alignment score is calculated by the following parameters:\n",
    "(parameters are taken from biopython)\n",
    "- match score = 1\n",
    "- mismatch score = -2\n",
    "- gap score = -2,5 \n",
    "- opening gap score = -1\n",
    "\n",
    "Opening gap score:\n",
    "- The first amino acid or nucleotide inserted/deleted (gap open) found during the alignment  is more significant, than the subsequent ones (gap extension)  https://seqan.readthedocs.io/en/main/zreferences.html#id24.\n",
    "- Appropriate gap scores have been selected over the years by trial and error  \n",
    " (Pearson, W.R. , 1995)\n",
    "\n",
    "## 4.1 Self Calculated Concensus Sequence Alignment (SCC):\n",
    "- concensus sequence of the most frequent amino acids in the alignemnt at each position\n",
    "- identification of mismatch positions\n",
    "- categorisation of mismatch-type in a bar plot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Translation of the concensus sequence in letter code \n",
    "aa = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "concensusseq = []\n",
    "for z,i in enumerate(concensus):\n",
    "    letter = aa[int(i)]\n",
    "    # print(letter)    \n",
    "    concensusseq.append(letter)\n",
    "\n",
    "print(concensusseq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Alignemnet of concensus sequence \n",
    "\n",
    "from Bio import Align\n",
    "from Bio import pairwise2\n",
    "aligner = Align.PairwiseAligner()\n",
    "\n",
    "#score \n",
    "Concensus_Calc = ''.join(concensusseq)\n",
    "score = pairwise2.align.globalms(Concensus_Calc, msa[0].seq, 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalms(Concensus_Calc, msa[0].seq, 1.0, 0.0, 0.0, 0.0)\n",
    "print(score[0].score)\n",
    "print(identical[0].score)\n",
    "#score = pairwise2.align.globalms(Concensus_Calc,msa[0].seq, score_only=True, match_score=1.0, mismatch_score=-1.0, gap_score = -1.5)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(Concensus_Calc,msa[0].seq, score[0].score, 23,286, full_sequences= False ) \n",
    "\n",
    "print(seq_Conc_Calc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.957883400Z"
    }
   },
   "outputs": [],
   "source": [
    "Concensus_Calc = ''.join(concensusseq)\n",
    "alignments = pairwise2.align.globalms(Concensus_Calc, msa[0].seq, 1.0, -2.0, -2.5, -1.0)\n",
    "PG_alignment = alignments[0]\n",
    "\n",
    "# Get mismatch positions\n",
    "mismatch_positions_SCC = []\n",
    "for i, (c1, c2) in enumerate(zip(PG_alignment.seqA, PG_alignment.seqB)):\n",
    "    if i > 23 and c1 != c2:\n",
    "        mismatch_positions_SCC.append(i+1)\n",
    "\n",
    "# Output mismatch positions\n",
    "print(\"Mismatch positions with index > 23:\")\n",
    "print(mismatch_positions_SCC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df_SCC = C_df_New[C_df_New['Position'].isin(mismatch_positions_SCC)]\n",
    "\n",
    "x = np.arange(len(filtered_df_SCC))\n",
    "width = 0.35\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4 ) = plt.subplots(1, 4, figsize=(50, 20))\n",
    "\n",
    "rects1 = ax1.bar(x, filtered_df_SCC['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects2 = ax1.bar(x, filtered_df_SCC['mean_all_z'], width, label='merged DMS')\n",
    "\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Shannon Entropy & Merged')\n",
    "ax1.legend()\n",
    "\n",
    "rects3 = ax2.bar(x, filtered_df_SCC['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects4 = ax2.bar(x, filtered_df_SCC['mean_Stiffler_z'], width, label='mean Stiffler')\n",
    "\n",
    "ax1.set_xticklabels(mismatch_positions_SCC)\n",
    "\n",
    "ax2.set_xticklabels(mismatch_positions_SCC)\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Scores')\n",
    "ax2.set_title('Shannon Entropy & Stiffler')\n",
    "ax2.legend()\n",
    "\n",
    "rects5 = ax3.bar(x, filtered_df_SCC['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects6 = ax3.bar(x, filtered_df_SCC['mean_Firnberg_z'], width, label='mean Firnberg')\n",
    "ax3.set_xlabel('Position')\n",
    "ax3.set_ylabel('Scores')\n",
    "ax3.set_title(' Shannon Entropy & Firnberg')\n",
    "ax3.legend()\n",
    "\n",
    "rects7 = ax4.bar(x, filtered_df_SCC['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects8 = ax4.bar(x, filtered_df_SCC['mean_Deng_z'], width, label='mean Deng')\n",
    "ax4.set_xlabel('Position')\n",
    "ax4.set_ylabel('Scores')\n",
    "ax4.set_title(' Shannon Entropy & Deng')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "The DMS mean and conservation distribution of the mismatch position is quite similar in all DMS data sets. Predominantly present are \"Random Positions\" (DMS and conservation is positive which indicates robustness and variance). Which is consistent with our expectation, as these regions can accumulate mutations without impact.\n",
    "Positions of interest should be conserved and do not occur except in the deng distribution, while destructive positions and unnecessary conserved positions occur only marginally.  \n",
    "That is a good result which supports the hypothesis that conservation correlates with DMS.\n",
    "\n",
    "Mismatches = 34\n",
    "  - Random Positions: 13-17  \n",
    "  - Destructive positions: 2  \n",
    " - Positions of interest: 1\n",
    " - Unneccessary conserved position: 2\n",
    " - Unclear Positions: 12\n",
    "\n",
    "\n",
    "Problems: \n",
    " - no gradual differentiation of the varaince in amino acids distribution, only the most frequent one is taken \n",
    "                \n",
    "Further approach: \n",
    " - calculation of conscensus sequence with alignment matrix from Emboss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Emboss Concensus Sequence Alignment (ECS)\n",
    "\n",
    "EMBOSS cons is a program which creates a consensus sequence by weights and scoring matrix values for a multiple sequence alignment. Therefore, every amino acids type at one residue is given a are score, composed of the weight (defined by the alignment file), multiplied with a scoring matrix value and the residue length. The highest scored amino acid is then found and must be greater than the “plurality value” which is defined by the user to set a “cut- off” of matches in the alignment. The highest scored amino acid above the “cut- off ” is inserted in the consensus sequence. If no amino acid reaches the “plurality value” a gap is inserted (emboss.open-bio.org).\n",
    "\n",
    "PAM point accepted substitution matrix:\n",
    "This substitution matrix is based on point mutation data from 71 phylogenetic tress with 1572 mutations in total (Jia K, 2021). The difference between the PAM matrices lays in the length of evolutional distance between the aligned proteins. The score of the PAM matrix indicates the distance of the sequences, while increasing scores indicate greater distance. (Mount DW, 2008)\n",
    "\n",
    "BLOSUM block substitution matrices\n",
    "BLOSUM matrices are the most common matrices used in MSA. They are not extrapolated by phylogenetic trees like PAM but constructed by alignment data of local alignments. The BLOSUM62 matrix serves as default matrix at NCBI as it describes alignments with wide ranging identities the best (Jia K, 2021).  The higher the number of the BLOSUM matrix the closer is the relation of the aligned sequences and therefore the higher is the identity (Pearson WR, 2013). The identity of TEM-1 alignment reaches from 47.5% to 100% with a huge proportion of around 90%. Therefore BLOSUM62,  BLOSUM90 are used. For reference values consensus sequences of PAM250 (which should be similar to BLOSUM62) and PAM460 are aligned with TEM-1.\n",
    "\n",
    "\n",
    "The following matrixes where used for concensus calculation: \n",
    "- Blosum62 \n",
    "- PAM250 for verification of Blosum62 results\n",
    "- Blosum90 \n",
    "- PAM460 for reference of bad alignment score values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#EMBOSS CONCENSUS EBLOSUM62\n",
    "with open(\"dataSources/MSA_datasets/emboss_cons_blosum62.txt\", \"r\") as file:\n",
    "    Conc_E62 = file.read()\n",
    "    seq_Conc_E62 = Conc_E62.replace(\"x\", \"-\")\n",
    "    seq_Conc_E62 = seq_Conc_E62[11:]\n",
    "print(seq_Conc_E62)\n",
    "\n",
    "aligner.match_score = 1.0\n",
    "aligner.mismatch_score = -2.0\n",
    "aligner.gap_score = -2.5\n",
    "score = pairwise2.align.globalms(seq_Conc_E62, msa[0].seq, 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalxx(seq_Conc_E62.strip(),msa[0].seq.strip(), score_only=True)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(seq_Conc_E62.strip(),msa[0].seq.strip(), score[0].score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc)\n",
    "print(score[0].score)\n",
    "print(identical)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#EMBOSS CONCENSUS PAM250\n",
    "with open(\"dataSources/MSA_datasets/emboss_cons-PAM250.txt\", \"r\") as file:\n",
    "    Conc_PAM250 = file.read()\n",
    "    seq_Conc_PAM250 = Conc_PAM250.replace(\"x\", \"-\")\n",
    "    seq_Conc_PAM250 = seq_Conc_PAM250[11:]\n",
    "print(seq_Conc_PAM250)\n",
    "\n",
    "aligner.match_score = 1.0\n",
    "aligner.mismatch_score = -2.0\n",
    "aligner.gap_score = -2.5\n",
    "score = pairwise2.align.globalxx(seq_Conc_PAM250,msa[0].seq, score_only=True)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(seq_Conc_PAM250.strip(),msa[0].seq.strip(), score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "# PAM250 and Blosum62 how strongly do they match ?\n",
    "aligner.match_score = 1.0\n",
    "aligner.mismatch_score = -2.0\n",
    "aligner.gap_score = -2.5\n",
    "score = pairwise2.align.globalxx(seq_Conc_PAM250,seq_Conc_E62, score_only=True)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(seq_Conc_PAM250.strip(),seq_Conc_E62.strip(), score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#EMBOSS CONCENSUS Blosum90\n",
    "with open(\"dataSources/MSA_datasets/blosum90.txt\", \"r\") as file:\n",
    "    Conc_B90 = file.read()\n",
    "    seq_Conc_B90 = Conc_B90.replace(\"x\", \"-\")\n",
    "    seq_Conc_B90 = seq_Conc_B90[11:]\n",
    "\n",
    "\n",
    "score = pairwise2.align.globalms(seq_Conc_B90, msa[0].seq, 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalxx(seq_Conc_B90,msa[0].seq, score_only=True)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(seq_Conc_B90.strip(),msa[0].seq.strip(), score[0].score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc)\n",
    "print(score[0].score)\n",
    "print(identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#EMBOSS Concensussequnez zur überprüfung PAM460\n",
    "with open(\"dataSources/MSA_datasets/emboss_cons_PAM460.txt\", \"r\") as file:\n",
    "    Conc_E = file.read()\n",
    "    seq_Conc_E = Conc_E.replace(\"x\", \"-\")\n",
    "    seq_Conc_E = seq_Conc_E[12:]\n",
    "\n",
    "print(seq_Conc_E)\n",
    "aligner.match_score = 1.0\n",
    "aligner.mismatch_score = -2.0\n",
    "aligner.gap_score = -2.5\n",
    "score = pairwise2.align.globalms(seq_Conc_E, msa[0].seq, 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalxx(seq_Conc_E.strip(),msa[0].seq.strip(), score_only=True)\n",
    "seq_Conc_Calc = Bio.pairwise2.format_alignment(seq_Conc_E,msa[0].seq, score[0].score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc)\n",
    "print(score[0].score)\n",
    "print(identical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Short validation that the alignment with biopython works (Self- alignment of TEM_1) \n",
    "with open(\"dataSources/MSA_datasets/Tem1.txt\", \"r\") as file:\n",
    "    TEM= file.read()\n",
    "    TEM_S = TEM[84:]#Title goes to Position 84 \n",
    "\n",
    "score = pairwise2.align.globalms(TEM_S.strip(),str(msa[0].seq.strip()), 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalxx(TEM_S.strip(),str(msa[0].seq.strip()), score_only=True)\n",
    "seq_Conc_Calc_T = Bio.pairwise2.format_alignment(TEM_S.strip(),str(msa[0].seq.strip()), score[0].score, 23,286, full_sequences= False ) \n",
    "print(seq_Conc_Calc_T)\n",
    "print(identical)\n",
    "print(score[0].score)\n",
    "\n",
    "#scoring and alignemnt is correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: \n",
    "1. EMBOSS Concensus Alignment:\n",
    "- The match scores from all three ECS's are nearly identical (range = 193 -195)\n",
    "- The ECS Identity of all three ECS’s lays in range of I=73.4% -74.1%\n",
    "- The alignment scores are as follows; BLOSUM62 (S=2), PAM250 (S=-1), BLOSUM90 (S=-1.5)\n",
    "- The reference PAM460 alignment score (score = -94.5) differs by 93-96.5 scoring points from the previous ECS's.  \n",
    "    Concludingly Blosum62, Blosum90 and PAM250 concensus sequences are very similar and the difference in their alignment scores can be neglected.\n",
    "\n",
    "2. EMBOSS concensus sequence (ECS) vs. Self calculated concensus (SCC):\n",
    "The results of SCC might be inaccurate because only the most frequent amino acid in the alignment is taken. Whereas the EMBOSS alignemnt calculates the concensus sequence based on big data sets and mathematical constructed matrixes.\n",
    "Therefore it can be assuemed that the the concensus sequences from ECS are more valid than SCC.  \n",
    "\n",
    "However the quality of the alignment itself was found to be higher for SCC (score = 115) than of ECS (score = -1.5/-1). Because the high number of matches lowers the alignments cost (SCC score = 229, ECS score = 193-195).\n",
    "\n",
    "3. Optimization of concensus sequence by calculating the sequence with emboss BLOSUM90 and aligning it with EMBOSS BLOSUM90 could lead to better alignment score while maintaining a more valid concensus sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Optimization of BLOSUM90 Alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "dict = {}\n",
    "Needle = r'dataSources/MSA_datasets/Needle_B90.txt'\n",
    "\n",
    "sequences = AlignIO.read(Needle, \"emboss\")\n",
    "for i, record in enumerate(sequences):\n",
    "    key = i\n",
    "    dict[key] = record.seq\n",
    "print(dict)\n",
    "#0 = TEM, 1 = Concensus\n",
    "\n",
    "#Alignment of Blosum90 with TEM-1 from Emboss\n",
    "alignmentB90 = pairwise2.align.globalms(dict[0].strip(),dict[1].strip(), 1.0, -2.0, -2.5, -1.0)\n",
    "identical = pairwise2.align.globalxx(dict[0].strip(),dict[1].strip(), score_only=True)\n",
    "seq_B90_TEM = Bio.pairwise2.format_alignment(dict[0].strip(),dict[1].strip(), alignmentB90[0].score, 23,308, full_sequences= False ) \n",
    "print(seq_B90_TEM)\n",
    "print(alignmentB90[0].score)\n",
    "print(identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#gap which needs to be subtracted to get the actuall TEM-1 position\n",
    "len(str('------------------------------'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.973509400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get  mismatch positions\n",
    "PG_alignment = alignmentB90[0]\n",
    "mismatch_position_90= []\n",
    "for i, (c1, c2) in enumerate(zip(PG_alignment.seqA, PG_alignment.seqB)):\n",
    "    if i > 59 and c1 != c2:\n",
    "        mismatch_position_90.append(i+1-30)\n",
    "        \n",
    "print(\"Mismatch positions with index > 23:\")\n",
    "print(mismatch_position_90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = C_df_New[C_df_New['Position'].isin(mismatch_position_90)]\n",
    "\n",
    "x = np.arange(len(filtered_df))\n",
    "width = 0.35\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4 ) = plt.subplots(1, 4, figsize=(60, 20))\n",
    "\n",
    "rects1 = ax1.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects2 = ax1.bar(x, filtered_df['mean_all_z'], width, label='merged DMS')\n",
    "\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Shannon Entropy & Merged')\n",
    "ax1.legend()\n",
    "\n",
    "rects3 = ax2.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects4 = ax2.bar(x, filtered_df['mean_Stiffler_z'], width, label='mean Stiffler')\n",
    "\n",
    "ax1.set_xticklabels(mismatch_position_90)\n",
    "ax2.set_xticklabels(mismatch_position_90)\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Scores')\n",
    "ax2.set_title('Shannon Entropy & Stiffler')\n",
    "ax2.legend()\n",
    "\n",
    "rects5 = ax3.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects6 = ax3.bar(x, filtered_df['mean_Firnberg_z'], width, label='mean Firnberg')\n",
    "ax3.set_xlabel('Position')\n",
    "ax3.set_ylabel('Scores')\n",
    "ax3.set_title(' Shannon Entropy & Firnberg')\n",
    "ax3.legend()\n",
    "\n",
    "rects7 = ax4.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects8 = ax4.bar(x, filtered_df['mean_Deng_z'], width, label='mean Deng')\n",
    "ax4.set_xlabel('Position')\n",
    "ax4.set_ylabel('Scores')\n",
    "ax4.set_title(' Shannon Entropy & Deng')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "  Alignment score = 25  \n",
    "  Matches = 222  \n",
    "  Mismatches = 84  \n",
    "\n",
    "- Random Positions: 26-29 \n",
    "- Destructive positions: 6-12  \n",
    " - Positions of interest: 20-25  \n",
    " - Unneccessary conserved position: 4-7\n",
    " - Unclear Positions: 15  \n",
    "\n",
    "Compared to the previous BLOSUM90 alignment, both the match score and the alignment score are higher and indicate a better quality (lower cost) within the alignment.\n",
    "\n",
    "\n",
    "The bar plots of all data sets are mostly consistent. In contrast to the SCC random positions do not predominate and no uniform distribution is detectable. Instead random positions and positions of interest seem to be equaly present. While random positions are consistent with our hypothesis, the huge number of positions of interest conflicts with our expectation as they should be conserved and not appear in the mismatch group. Moreover destructive positions and unneccessary positions are also found in the mismatch group. While in the deng data set unnecessary conserved position appear more often than in the other data sets. \n",
    "\n",
    "Overall the alignment score and identity still suggests that the emboss alignment is significantly better than the previous alignments. Thus mistakes and inaccuracies in the categorization might be possible. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extended: DMS trend at important positions\n",
    "\n",
    "Important positions which are expected to be conserved and fragile: \n",
    "- Active site : 68,166\n",
    "- Binding site: 232-234\n",
    "- Disulfid bond: 75-121\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Positions\n",
    "active_site = [68, 166]\n",
    "binding_site = list(range(232, 235))  \n",
    "disulfid_bond = list(range(75, 122))  \n",
    "positions = active_site + binding_site + disulfid_bond\n",
    "\n",
    "filtered_df = C_df_New[C_df_New['Position'].isin(positions)]\n",
    "\n",
    "\n",
    "x = np.arange(len(filtered_df))\n",
    "width = 0.35\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "rects1 = ax1.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects2 = ax1.bar(x, filtered_df['mean_all_z'], width, label='mean DMS')\n",
    "\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Mean DMS with Shannon Conservation')\n",
    "ax1.legend()\n",
    "\n",
    "rects3 = ax2.bar(x, filtered_df['Conserved_Shannon'], width, label='Shannon Conservation')\n",
    "rects4 = ax2.bar(x, filtered_df['mean_Stiffler_z'], width, label='mean Stiffler')\n",
    "\n",
    "\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Scores')\n",
    "ax2.set_title('Mean Stiffler with Shannon Conservation')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both barplots are predominantly composed of random positions and positions of interest. The proportion of destructive position is negligible low, similar to the rarely frequent unnecessary conserved positions. \n",
    "\n",
    "Merged model:\n",
    " - Destructive Positions:  4\n",
    " - Unneccessary Conserved: 5\n",
    "\n",
    "Stiffler:\n",
    "  - Destructive Positions: 3\n",
    "  - Unneccesssary Conserved: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculation of the average DMS in the structural or functional important positions\n",
    "mean_by_column = C_df_New.loc[C_df_New['Position'].isin(positions)].mean()\n",
    "print(mean_by_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "We expected that functional and structural important positions have high conservation and low DMS, thus belong to the category of positions of interest. \n",
    "In the bar plot the proportion of positions of interest is quite equal to the proportion of random positions which have low conservation but high robustness. \n",
    "\n",
    "DMS:\n",
    "Overall there is a high proportion of robust positions which contradicts our hypothesis, that important positions are fragile. \n",
    "The mean DMS values of the important positions lay around DMS = -0.063 - 0.063. That is close to mean fitness, thus we can not approve our expectation, that the DMS is more negative at these residues.\n",
    "\n",
    "Conservation:\n",
    "To be recognized on the conservation scores which lay around 0 (mean conservation) it can not be confirmed that important positions are higher or lower conserved as other positions.\n",
    "\n",
    "    mean_Stiffler_z        0.063633\n",
    "    mean_Deng_z           -0.062993\n",
    "    mean_Firnberg_z       -0.003927\n",
    "    mean_all_z             0.000635\n",
    "\n",
    "    Pei&Grishin            0.171609\n",
    "    Conserved_Shannon     -0.131827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extended Hypothesis Testing \n",
    "1. Assign each position as match or mismatch by the blosum62 matrix\n",
    "2. Check for normal distribution within the assigned position groups\n",
    "3. Apply Wilcoxon Signed Ranked test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_alignment(alignments):\n",
    "    lines = alignments.strip().split('\\n')\n",
    "    alignment_lines = lines[0:3]\n",
    "    seq1 = alignment_lines[0]\n",
    "    seq2 = alignment_lines[2]\n",
    "\n",
    "    df = pd.DataFrame(columns=['Position', 'Blossum62', 'TEM-1', 'Status'])\n",
    "\n",
    "    for i in range(len(seq1)):\n",
    "        aa1 = seq1[i]\n",
    "        aa2 = seq2[i]\n",
    "\n",
    "        if aa1 == aa2:\n",
    "            status = 'Identical'\n",
    "        elif aa1 == '-' or aa2 == '-':\n",
    "            status = 'Gap'\n",
    "        else:\n",
    "            status = 'Different'\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame({'Position': [i+1], 'Blossum62': [aa1], 'TEM-1': [aa2], 'Status': [status]})])\n",
    "\n",
    "    return df\n",
    "\n",
    "result = process_alignment(seq_Bl62_TEM)\n",
    "Concen_Align_Result = result.copy()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Data frame with mean DMS for the aligned residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mean = pd.read_pickle('dataSources/handovers/position_means.pkl')\n",
    "\n",
    "df_mean_c = df_mean[['mean_Stiffler_z', 'mean_Deng_z', 'mean_Firnberg_z', 'mean_all_z']].copy()\n",
    "\n",
    "Concen_Align_Result['mean'] = df_mean_c['mean_all_z']\n",
    "Concen_Align_Result['Stiffler'] = df_mean['mean_Stiffler_z'].shift(-1)\n",
    "\n",
    "Concen_Align_Result = Concen_Align_Result.reset_index(drop=True)\n",
    "\n",
    "\n",
    "Concen_Align_Result_short = Concen_Align_Result.iloc[23:286,:6]\n",
    "print(Concen_Align_Result_short)\n",
    "print (df_mean_c)\n",
    "\n",
    "#sometimes randomly this chunk produced only NaNs in Concen_Align_Result_short, this can be fixed by just running it again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Shapiro test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "data_identical = Concen_Align_Result_short[Concen_Align_Result_short['Status'] == 'Identical']['mean']\n",
    "data_different = Concen_Align_Result_short[Concen_Align_Result_short['Status'] == 'Different']['mean']\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "data = Concen_Align_Result_short['mean'].dropna()\n",
    "\n",
    "#Shapiro-Wilk-Test\n",
    "statistic, p_value = shapiro(data)\n",
    "print('Shapiro-Wilk-Test match:', statistic)\n",
    "print('Shapiro-Wilk-Test p-value:', p_value)\n",
    "\n",
    "\n",
    "data = data_different\n",
    "statistic, p_value = shapiro(data)\n",
    "print('Shapiro-Wilk-Test mismatch:', statistic)\n",
    "print('Shapiro-Wilk-Test p-value:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from Shapiro test: \n",
    "No normal distribution in the mismatch/match groups.\n",
    "\n",
    "Matches\n",
    "Shapiro-Wilk-Test match: 0.9446558356285095\n",
    "Shapiro-Wilk-Test p-value: 2.193244874604261e-08\n",
    "\n",
    "Missmatches: \n",
    "Shapiro-Wilk-Test mismatch: 0.9434723258018494\n",
    "Shapiro-Wilk-Test p-value: 0.007768177427351475"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wilcoxon Rank Sum Test \n",
    "Testing if groups of match and mismatch positions show group specific DMS trends. \n",
    "\n",
    "H0 = No difference in the distribution of DMS scores in match and mismatch groups\n",
    "- Two sided test\n",
    "\n",
    "Problem:\n",
    "Not the same size of both groups\n",
    "- matches = 186\n",
    "- mismatches = 60\n",
    "\n",
    "Approach:\n",
    "Random loop which pics 69 values from the match group\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example with 1000 iterations\n",
    "num_iterations = 1000 \n",
    "test_statistics = []\n",
    "p_values = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # choose random 69 values of the match group \n",
    "    random_identical_data = random.sample(list(data_identical ), 60)\n",
    "\n",
    "    # Wilcoxon- test\n",
    "    statistic, p_value = wilcoxon(random_identical_data, data_different)\n",
    "    test_statistics.append(statistic)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "\n",
    "mean_test_statistic = sum(test_statistics) / len(test_statistics)\n",
    "mean_p_value = sum(p_values) / len(p_values)\n",
    "\n",
    "print(mean_test_statistic)\n",
    "print(mean_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T12:13:44.989136200Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_identical[0:60], data_different)\n",
    "plt.scatter(data_identical[126:186], data_different, color = 'orange')\n",
    "plt.xlabel('Identical')\n",
    "plt.ylabel('Different')\n",
    "plt.title('Identical & Different DMS scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: \n",
    "\n",
    " 1000 Runs: \n",
    "     - Average test statistics: 1124.909\n",
    "     - Average p-value: 0.6478203616373306\n",
    "\n",
    "    10000 Runs:\n",
    "     - Average test statistics: 1122.9197\n",
    "     - Average p-value: 0.641155545963515\n",
    "\n",
    "     15000 Runs: \n",
    "    -  Average test statistics: 1123.9102666666668\n",
    "    - Average p-value: 0.6434579695313134\n",
    "\n",
    "    18000 Runs: \n",
    "    - Average test statistics: 1122.7196666666666\n",
    "    - Average p-value: 0.6405447963911712\n",
    "\n",
    "The p-value is not significant, therefore H0 hypothesis can not be rejected. Moreover the scatter plot distribution fluctuates with the 60 matches which are randomly choosen and does not show a correlation trend. Concludingly there is no significant difference in the distribution of the DMS values in the match or mismatch groups as we expected. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
